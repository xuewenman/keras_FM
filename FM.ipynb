{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow.keras.backend as bk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# import psutil\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the data\n",
    "\n",
    "# train_iter = pd.read_csv('train.csv', chunksize=10000, iterator=True)\n",
    "train_df = pd.read_csv(\"train.csv\", nrows=1000)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# train_df['hour'].map(lambda x:int(str(x)[6:])).unique()\n",
    "# train_df['device_type'].unique()\n",
    "def my_one_hot(df):\n",
    "    '''\n",
    "        one_hot_encode some categorical columns of the dataframe\n",
    "    '''\n",
    "    one_hot_cols = list(df.columns)\n",
    "    print(\"One hot encoding: \", one_hot_cols)\n",
    "    labelencoder = LabelEncoder() \n",
    "    one_hot_df = pd.DataFrame()\n",
    "\n",
    "    # only keep the hour information\n",
    "    # print(\"hour: \", , \"++++\")\n",
    "    if df.iloc[0]['hour']>24:\n",
    "        df['hour'] = df['hour'].map(lambda x:int(str(x)[6:]))\n",
    "\n",
    "    for encode_col in one_hot_cols:\n",
    "        cols_name = []\n",
    "        # Use label encoder to transform the data, so string and object type can be one_hot encoded\n",
    "        df[encode_col] = labelencoder.fit_transform(df[encode_col]) \n",
    "        for val in df[encode_col].unique(): # generate new col names\n",
    "            cols_name.append(encode_col+\"_LE=\"+str(val))\n",
    "        curr_df = pd.DataFrame(bk.one_hot(df[encode_col], len(df[encode_col].unique())).numpy(), columns=cols_name)\n",
    "        # df = df.drop([encode_col], axis=1) # drop the old column\n",
    "        one_hot_df = pd.concat([one_hot_df, curr_df], axis=1)\n",
    "    return one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove the nrows parameter\n",
    "def get_onehot_data():\n",
    "    '''\n",
    "        Read the train data and test data, put them together\n",
    "        use one hot encoding to make sure that train and test data have the same shape\n",
    "\n",
    "        Return: \n",
    "            one hot encoded train dataset and test dataset\n",
    "    '''\n",
    "    print(\"Reading data...\")\n",
    "    ori_df = pd.read_csv('train.csv', nrows=1000) # read the training data\n",
    "    ordered_cols = ori_df.columns # record the order of the columns, because the concat operation will change the col order\n",
    "    one_hot_cols = ordered_cols[2:] # we don't do one hot encoding to id and click\n",
    "    train_sample_num = ori_df.shape[0] # record the number of samples used for train, use this number to split the dataset after onehot encoding\n",
    "    print(\"Number of training sample: \", train_sample_num)\n",
    "\n",
    "    # onehot encode the test data\n",
    "    ori_df = pd.concat([ori_df, pd.read_csv('test.csv', nrows=2)], axis=0).reset_index(drop=True) # must rest the index, or the kernal will restart!!! (I don't know why)\n",
    "\n",
    "    # one_hot_data = my_one_hot(ori_df[one_hot_cols])\n",
    "    one_hot_df = pd.concat([ori_df[ordered_cols[:2]], my_one_hot(ori_df[one_hot_cols])], axis=1)\n",
    "    return [one_hot_df[:train_sample_num], one_hot_df[train_sample_num:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMCrossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, vector_len, **kwargs):\n",
    "        '''\n",
    "            output_dim: the dimension of the output of the cross layer\n",
    "            vector_len: the length of the implicit vector\n",
    "        '''\n",
    "        self.output_dim = output_dim\n",
    "        self.vector_len = vector_len\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.vectors = self.add_weight(\n",
    "            name='weights',\n",
    "            shape=(input_shape[1], self.vector_len), # shape is (number of features*vector_len)\n",
    "            initializer='uniform',\n",
    "            trainable=True)\n",
    "        super().build(input_shape) # to set self.built=True\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        # print('x:', x)\n",
    "        first_part = bk.square(bk.dot(x, self.vectors))\n",
    "        second_part = bk.dot(bk.square(x), bk.square(self.vectors))\n",
    "        output = bk.sum(first_part - second_part, axis=1) * 0.5 # sum over axis=1\n",
    "        return bk.reshape(output, (-1, self.output_dim))\n",
    "        # print(\"call\", first_part.shape, second_part.shape, self.vectors.shape)\n",
    "        # return output\n",
    "        \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return (input_shape[0], self.output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FM_model(feature_len=None, vector_len=5):\n",
    "    '''\n",
    "        Here we combine the linear features and cross features and get the full FM model. This function need the number of features and the length of the hidden vector(one hidden vector for each feature).\n",
    "    '''\n",
    "    output_dim = 1\n",
    "    print(\"Hidden vector length: \", vector_len)\n",
    "    # generate the input, linear features part and cross features part of FM\n",
    "    input_layer = tf.keras.Input(shape=(feature_len, ), name='input')\n",
    "    linear_layer = tf.keras.layers.Dense(output_dim, name='linear_layer')(input_layer)\n",
    "    cross_layer = FMCrossLayer(output_dim, vector_len, name='cross_layer')(input_layer)\n",
    "    # print(\"linear_layer.shape: \", linear_layer.shape)\n",
    "    # print(\"cross_layer.shape: \", cross_layer.shape)\n",
    "\n",
    "    # add the linear features part and crossed features part\n",
    "    combine = tf.keras.layers.Add(name='combine')([linear_layer, cross_layer])\n",
    "    # print(\"combine shape: \", combine.shape)\n",
    "\n",
    "    # use sigmoid to get the final result\n",
    "    # output = tf.keras.activations.sigmoid(combine)\n",
    "    output = tf.keras.layers.Dense(output_dim, activation='sigmoid', name='output')(combine)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.optimizers.Adam(0.001),\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_hidden_weights(model=None):\n",
    "    '''\n",
    "        Get the hidden vectors of FM, for better understanding\n",
    "    '''\n",
    "    return model.get_layer('cross_layer').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(vector_len=5, epochs=10, verbose=1, batchsize=1024, test_size=0.2, seed=15):\n",
    "    '''\n",
    "        Get the FM model, split the data and train the model\n",
    "        Inputs:\n",
    "            vector_len: length of the hidden vector\n",
    "    '''\n",
    "    # print(\"Reading the data...\")\n",
    "    target = 'click'\n",
    "\n",
    "    train, test = get_onehot_data()\n",
    "    cols = train.columns\n",
    "    train_x = train[cols[2:]]\n",
    "    train_label = train[[target]]\n",
    "\n",
    "    print(\"Shape of train_x: \", train_x.shape)    \n",
    "\n",
    "    # test data from kaggle don't have click result, so just use validation_split while training\n",
    "    # test_x = test[cols[2:]]\n",
    "    # test_label = test[[target]]\n",
    "\n",
    "    print(\"Generating the model...\")\n",
    "    fm_model = get_FM_model(train_x.shape[1], vector_len)\n",
    "\n",
    "    print(\"Training the model...\")\n",
    "    fm_model.fit(train_x, train_label, epochs=epochs, batch_size=batchsize, validation_split=test_size)\n",
    "    return fm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Reading data...\nNumber of training sample:  1000\nOne hot encoding:  ['hour', 'C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', 'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\nShape of train_x:  (1000, 2024)\nGenerating the model...\nHidden vector length:  5\nModel: \"model_24\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              [(None, 2024)]       0                                            \n__________________________________________________________________________________________________\nlinear_layer (Dense)            (None, 1)            2025        input[0][0]                      \n__________________________________________________________________________________________________\ncross_layer (FMCrossLayer)      (None, 1)            10120       input[0][0]                      \n__________________________________________________________________________________________________\ncombine (Add)                   (None, 1)            0           linear_layer[0][0]               \n                                                                 cross_layer[0][0]                \n__________________________________________________________________________________________________\noutput (Dense)                  (None, 1)            2           combine[0][0]                    \n==================================================================================================\nTotal params: 12,147\nTrainable params: 12,147\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nTraining the model...\nTrain on 800 samples, validate on 200 samples\nEpoch 1/10\n800/800 [==============================] - 1s 1ms/sample - loss: 0.6836 - binary_accuracy: 0.6737 - val_loss: 0.6802 - val_binary_accuracy: 0.7100\nEpoch 2/10\n800/800 [==============================] - 0s 34us/sample - loss: 0.6791 - binary_accuracy: 0.7425 - val_loss: 0.6767 - val_binary_accuracy: 0.7250\nEpoch 3/10\n800/800 [==============================] - 0s 24us/sample - loss: 0.6747 - binary_accuracy: 0.7775 - val_loss: 0.6732 - val_binary_accuracy: 0.7700\nEpoch 4/10\n800/800 [==============================] - 0s 26us/sample - loss: 0.6704 - binary_accuracy: 0.8075 - val_loss: 0.6698 - val_binary_accuracy: 0.7950\nEpoch 5/10\n800/800 [==============================] - 0s 22us/sample - loss: 0.6661 - binary_accuracy: 0.8300 - val_loss: 0.6665 - val_binary_accuracy: 0.8050\nEpoch 6/10\n800/800 [==============================] - 0s 22us/sample - loss: 0.6618 - binary_accuracy: 0.8388 - val_loss: 0.6631 - val_binary_accuracy: 0.8100\nEpoch 7/10\n800/800 [==============================] - 0s 24us/sample - loss: 0.6576 - binary_accuracy: 0.8487 - val_loss: 0.6598 - val_binary_accuracy: 0.8050\nEpoch 8/10\n800/800 [==============================] - 0s 24us/sample - loss: 0.6534 - binary_accuracy: 0.8475 - val_loss: 0.6565 - val_binary_accuracy: 0.8150\nEpoch 9/10\n800/800 [==============================] - 0s 22us/sample - loss: 0.6492 - binary_accuracy: 0.8512 - val_loss: 0.6532 - val_binary_accuracy: 0.8200\nEpoch 10/10\n800/800 [==============================] - 0s 22us/sample - loss: 0.6451 - binary_accuracy: 0.8487 - val_loss: 0.6499 - val_binary_accuracy: 0.8200\n"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    fm = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}