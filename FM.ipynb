{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow.keras.backend as bk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                     id  click      hour    C1  banner_pos   site_id  \\\n0   1000009418151094273      0  14102100  1005           0  1fbe01fe   \n1  10000169349117863715      0  14102100  1005           0  1fbe01fe   \n2  10000371904215119486      0  14102100  1005           0  1fbe01fe   \n3  10000640724480838376      0  14102100  1005           0  1fbe01fe   \n4  10000679056417042096      0  14102100  1005           1  fe8cc448   \n\n  site_domain site_category    app_id app_domain app_category device_id  \\\n0    f3845767      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a   \n1    f3845767      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a   \n2    f3845767      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a   \n3    f3845767      28905ebd  ecad2386   7801e8d9     07d7df22  a99f214a   \n4    9166c161      0569f928  ecad2386   7801e8d9     07d7df22  a99f214a   \n\n  device_ip device_model  device_type  device_conn_type    C14  C15  C16  \\\n0  ddd2926e     44956a24            1                 2  15706  320   50   \n1  96809ac8     711ee120            1                 0  15704  320   50   \n2  b3cf8def     8a4875bd            1                 0  15704  320   50   \n3  e8275b8f     6332421a            1                 0  15706  320   50   \n4  9644d0bf     779d90c2            1                 0  18993  320   50   \n\n    C17  C18  C19     C20  C21  \n0  1722    0   35      -1   79  \n1  1722    0   35  100084   79  \n2  1722    0   35  100084   79  \n3  1722    0   35  100084   79  \n4  2161    0   35      -1  157  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>click</th>\n      <th>hour</th>\n      <th>C1</th>\n      <th>banner_pos</th>\n      <th>site_id</th>\n      <th>site_domain</th>\n      <th>site_category</th>\n      <th>app_id</th>\n      <th>app_domain</th>\n      <th>app_category</th>\n      <th>device_id</th>\n      <th>device_ip</th>\n      <th>device_model</th>\n      <th>device_type</th>\n      <th>device_conn_type</th>\n      <th>C14</th>\n      <th>C15</th>\n      <th>C16</th>\n      <th>C17</th>\n      <th>C18</th>\n      <th>C19</th>\n      <th>C20</th>\n      <th>C21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1000009418151094273</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>1fbe01fe</td>\n      <td>f3845767</td>\n      <td>28905ebd</td>\n      <td>ecad2386</td>\n      <td>7801e8d9</td>\n      <td>07d7df22</td>\n      <td>a99f214a</td>\n      <td>ddd2926e</td>\n      <td>44956a24</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15706</td>\n      <td>320</td>\n      <td>50</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>35</td>\n      <td>-1</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>10000169349117863715</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>1fbe01fe</td>\n      <td>f3845767</td>\n      <td>28905ebd</td>\n      <td>ecad2386</td>\n      <td>7801e8d9</td>\n      <td>07d7df22</td>\n      <td>a99f214a</td>\n      <td>96809ac8</td>\n      <td>711ee120</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15704</td>\n      <td>320</td>\n      <td>50</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>35</td>\n      <td>100084</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>10000371904215119486</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>1fbe01fe</td>\n      <td>f3845767</td>\n      <td>28905ebd</td>\n      <td>ecad2386</td>\n      <td>7801e8d9</td>\n      <td>07d7df22</td>\n      <td>a99f214a</td>\n      <td>b3cf8def</td>\n      <td>8a4875bd</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15704</td>\n      <td>320</td>\n      <td>50</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>35</td>\n      <td>100084</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>10000640724480838376</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>1fbe01fe</td>\n      <td>f3845767</td>\n      <td>28905ebd</td>\n      <td>ecad2386</td>\n      <td>7801e8d9</td>\n      <td>07d7df22</td>\n      <td>a99f214a</td>\n      <td>e8275b8f</td>\n      <td>6332421a</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15706</td>\n      <td>320</td>\n      <td>50</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>35</td>\n      <td>100084</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10000679056417042096</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>1</td>\n      <td>fe8cc448</td>\n      <td>9166c161</td>\n      <td>0569f928</td>\n      <td>ecad2386</td>\n      <td>7801e8d9</td>\n      <td>07d7df22</td>\n      <td>a99f214a</td>\n      <td>9644d0bf</td>\n      <td>779d90c2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>18993</td>\n      <td>320</td>\n      <td>50</td>\n      <td>2161</td>\n      <td>0</td>\n      <td>35</td>\n      <td>-1</td>\n      <td>157</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# explore the data\n",
    "train_df = pd.read_csv(\"train.csv\", nrows=1000)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def my_one_hot(df):\n",
    "    '''\n",
    "        one_hot_encode some categorical columns of the dataframe\n",
    "    '''\n",
    "    one_hot_cols = list(df.columns)\n",
    "    print(\"One hot encoding: \", one_hot_cols)\n",
    "    labelencoder = LabelEncoder() \n",
    "    one_hot_df = pd.DataFrame()\n",
    "\n",
    "    # only keep the hour information\n",
    "    if df.iloc[0]['hour']>24:\n",
    "        df['hour'] = df['hour'].map(lambda x:int(str(x)[6:]))\n",
    "\n",
    "    for encode_col in one_hot_cols:\n",
    "        cols_name = []\n",
    "        # Use label encoder to transform the data, so string and object type can be one_hot encoded\n",
    "        df[encode_col] = labelencoder.fit_transform(df[encode_col])\n",
    "        \n",
    "        for val in df[encode_col].unique(): # generate new col names\n",
    "            cols_name.append(encode_col+\"_LE=\"+str(val))\n",
    "        \n",
    "        curr_df = pd.DataFrame(bk.one_hot(df[encode_col], len(df[encode_col].unique())).numpy(), columns=cols_name)\n",
    "        one_hot_df = pd.concat([one_hot_df, curr_df], axis=1)\n",
    "\n",
    "    return one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I used the nrows parameter in read_csv, in order to make debug process faster\n",
    "def get_onehot_data():\n",
    "    '''\n",
    "        Read the train data and test data, put them together\n",
    "        Use one hot encoding to make sure that train and test data have the same shape\n",
    "\n",
    "        Return: \n",
    "            one hot encoded train dataset and test dataset\n",
    "    '''\n",
    "    print(\"Reading data...\")\n",
    "    ori_df = pd.read_csv('train.csv', nrows=1000)\n",
    "\n",
    "    # record the order of the columns, because the concat operation will change the col order\n",
    "    ordered_cols = ori_df.columns\n",
    "\n",
    "    # we don't do one hot encoding to 'id' and 'click'\n",
    "    one_hot_cols = ordered_cols[2:] \n",
    "    \n",
    "    # use this number to split the dataset after onehot encoding(if needed)\n",
    "    train_sample_num = ori_df.shape[0]\n",
    "    print(\"Number of training sample: \", train_sample_num)\n",
    "\n",
    "    # onehot encode the test data, must rest the index(or the kernal will restart!!! (I don't know why))\n",
    "    ori_df = pd.concat([ori_df, pd.read_csv('test.csv', nrows=2)], axis=0).reset_index(drop=True) # \n",
    "\n",
    "    one_hot_df = pd.concat([ori_df[ordered_cols[:2]], my_one_hot(ori_df[one_hot_cols])], axis=1)\n",
    "    return [one_hot_df[:train_sample_num], one_hot_df[train_sample_num:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMCrossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, vector_len, **kwargs):\n",
    "        '''\n",
    "            output_dim: the dimension of the output of the cross layer\n",
    "            vector_len: the length of the implicit vector\n",
    "        '''\n",
    "        self.output_dim = output_dim\n",
    "        self.vector_len = vector_len\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''\n",
    "            set the weights for the layer\n",
    "        '''\n",
    "        self.vectors = self.add_weight(\n",
    "            name='weights',\n",
    "            shape=(input_shape[1], self.vector_len), # shape is (feature_len * vector_len)\n",
    "            initializer='uniform',\n",
    "            trainable=True)\n",
    "        super().build(input_shape) # set self.built=True\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        '''\n",
    "            here we define the forward propagatation\n",
    "        '''\n",
    "        first_part = bk.square(bk.dot(x, self.vectors))\n",
    "        second_part = bk.dot(bk.square(x), bk.square(self.vectors))\n",
    "        output = bk.sum(first_part - second_part, axis=1) * 0.5 # sum over axis=1\n",
    "        return bk.reshape(output, (-1, self.output_dim))\n",
    "        \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return (input_shape[0], self.output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FM_model(feature_len=None, vector_len=5):\n",
    "    '''\n",
    "        Here we combine the linear features and cross features and get the full FM model. \n",
    "        This function need the number of features and the length of the hidden vector(one hidden vector for each feature).\n",
    "\n",
    "        Inputs:\n",
    "            feature_len: number of the fatures (after one-hot encode)\n",
    "            vector_len: length of the hidden vector(a hyper-parameter), set to 5 by default\n",
    "        Outputs:\n",
    "            model: fm_model\n",
    "    '''\n",
    "    output_dim = 1\n",
    "    print(\"Hidden vector length: \", vector_len)\n",
    "\n",
    "    # generate the input, linear features part and cross features part of FM\n",
    "    input_layer = tf.keras.Input(shape=(feature_len, ), name='input')\n",
    "    linear_layer = tf.keras.layers.Dense(output_dim, name='linear_layer')(input_layer)\n",
    "    cross_layer = FMCrossLayer(output_dim, vector_len, name='cross_layer')(input_layer)\n",
    "\n",
    "    # add the linear features part and crossed features part\n",
    "    combine = tf.keras.layers.Add(name='combine')([linear_layer, cross_layer])\n",
    "\n",
    "    # use sigmoid to get the final result\n",
    "    output = tf.keras.layers.Dense(output_dim, activation='sigmoid', name='output')(combine)\n",
    "\n",
    "    # compile the model\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.optimizers.Adam(0.001),\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_hidden_weights(model=None):\n",
    "    '''\n",
    "        Get the hidden vectors of FM, for better understanding\n",
    "    '''\n",
    "    return model.get_layer('cross_layer').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(vector_len=5, epochs=10, verbose=1, batchsize=1024, test_size=0.2):\n",
    "    '''\n",
    "        Get the FM model, split the data and train the model\n",
    "        Inputs:\n",
    "            vector_len: length of the hidden vector\n",
    "            epochs:\n",
    "            verbose:\n",
    "            batchsize:\n",
    "            test_size:\n",
    "    '''\n",
    "    target = 'click'\n",
    "    train, test = get_onehot_data()\n",
    "    \n",
    "    cols = train.columns\n",
    "    train_x = train[cols[2:]]\n",
    "    train_label = train[[target]]\n",
    "\n",
    "    print(\"Shape of train_x: \", train_x.shape)    \n",
    "\n",
    "    # test data from kaggle don't have click result, so just use validation_split while training\n",
    "    # test_x = test[cols[2:]]\n",
    "    # test_label = test[[target]]\n",
    "\n",
    "    print(\"Generating the model...\")\n",
    "    fm_model = get_FM_model(train_x.shape[1], vector_len)\n",
    "\n",
    "    print(\"Training the model...\")\n",
    "    fm_model.fit(train_x, train_label, epochs=epochs, batch_size=batchsize, validation_split=test_size)\n",
    "    return fm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Reading data...\nNumber of training sample:  1000\nOne hot encoding:  ['hour', 'C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', 'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\nShape of train_x:  (1000, 2024)\nGenerating the model...\nHidden vector length:  5\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              [(None, 2024)]       0                                            \n__________________________________________________________________________________________________\nlinear_layer (Dense)            (None, 1)            2025        input[0][0]                      \n__________________________________________________________________________________________________\ncross_layer (FMCrossLayer)      (None, 1)            10120       input[0][0]                      \n__________________________________________________________________________________________________\ncombine (Add)                   (None, 1)            0           linear_layer[0][0]               \n                                                                 cross_layer[0][0]                \n__________________________________________________________________________________________________\noutput (Dense)                  (None, 1)            2           combine[0][0]                    \n==================================================================================================\nTotal params: 12,147\nTrainable params: 12,147\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nTraining the model...\nTrain on 800 samples, validate on 200 samples\nEpoch 1/10\n800/800 [==============================] - 1s 1ms/sample - loss: 0.7688 - binary_accuracy: 0.2062 - val_loss: 0.7534 - val_binary_accuracy: 0.2250\nEpoch 2/10\n800/800 [==============================] - 0s 25us/sample - loss: 0.7531 - binary_accuracy: 0.2400 - val_loss: 0.7413 - val_binary_accuracy: 0.2550\nEpoch 3/10\n800/800 [==============================] - 0s 25us/sample - loss: 0.7386 - binary_accuracy: 0.2875 - val_loss: 0.7301 - val_binary_accuracy: 0.2850\nEpoch 4/10\n800/800 [==============================] - 0s 26us/sample - loss: 0.7250 - binary_accuracy: 0.3462 - val_loss: 0.7195 - val_binary_accuracy: 0.3400\nEpoch 5/10\n800/800 [==============================] - 0s 30us/sample - loss: 0.7122 - binary_accuracy: 0.4250 - val_loss: 0.7095 - val_binary_accuracy: 0.4050\nEpoch 6/10\n800/800 [==============================] - 0s 29us/sample - loss: 0.7000 - binary_accuracy: 0.5188 - val_loss: 0.6998 - val_binary_accuracy: 0.4700\nEpoch 7/10\n800/800 [==============================] - 0s 26us/sample - loss: 0.6882 - binary_accuracy: 0.5775 - val_loss: 0.6905 - val_binary_accuracy: 0.5250\nEpoch 8/10\n800/800 [==============================] - 0s 27us/sample - loss: 0.6769 - binary_accuracy: 0.6438 - val_loss: 0.6816 - val_binary_accuracy: 0.6300\nEpoch 9/10\n800/800 [==============================] - 0s 26us/sample - loss: 0.6659 - binary_accuracy: 0.6888 - val_loss: 0.6729 - val_binary_accuracy: 0.6850\nEpoch 10/10\n800/800 [==============================] - 0s 30us/sample - loss: 0.6553 - binary_accuracy: 0.7387 - val_loss: 0.6646 - val_binary_accuracy: 0.7100\n"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    fm = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}